{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Unit 2.3 Extracting Information from Data, Pandas\n",
    "> Data connections, trends, and correlation.  Pandas is introduced as it could be valuable for PBL, data validation, as well as understanding College Board Topics.\n",
    "- toc: true\n",
    "- image: /images/python.png\n",
    "- categories: []\n",
    "- type: ap\n",
    "- week: 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- Pandas allows for easy organization and reading of data\n",
    "- Datasets must be clean before feeding them to a computer\n",
    "  - this can be improved with pandas\n",
    "- When creating or using a dataset you must consider;\n",
    "  - Does it have a good sample size?\n",
    "  - Is there bias in the data?\n",
    "  - Does the data set need to be cleaned?\n",
    "  - What is the purpose of the data set?\n",
    "\n",
    "\n",
    "# Pandas and DataFrames\n",
    "> In this lesson we will be exploring data analysis using Pandas.  \n",
    "\n",
    "- College Board talks about ideas like \n",
    "    - Tools. \"the ability to process data depends on users capabilities and their tools\"\n",
    "    - Combining Data.  \"combine county data sets\"\n",
    "    - Status on Data\"determining the artist with the greatest attendance during a particular month\"\n",
    "    - Data poses challenge. \"the need to clean data\", \"incomplete data\"\n",
    "\n",
    "\n",
    "- [From Pandas Overview](https://pandas.pydata.org/docs/getting_started/index.html) -- When working with tabular data, such as data stored in spreadsheets or databases, pandas is the right tool for you. pandas will help you to explore, clean, and process your data. In pandas, a data table is called a DataFrame.\n",
    "\n",
    "\n",
    "![DataFrame](images/table_dataframe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pandas is used to gather data sets through its DataFrames implementation'''\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "When looking at a data set, check to see what data needs to be cleaned. Examples include:\n",
    "- Missing Data Points\n",
    "- Invalid Data\n",
    "- Inaccurate Data\n",
    "\n",
    "Run the following code to see what needs to be cleaned\n",
    "\n",
    "  - This code defines 'df'(dataframe) by getting the data from 'grade.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID Year in School   GPA\n",
      "0         123             12  3.57\n",
      "1         246             10  4.00\n",
      "2         578             12  2.78\n",
      "3         469             11  3.45\n",
      "4         324         Junior  4.75\n",
      "5         313             20  3.33\n",
      "6         145             12  2.95\n",
      "7         167             10  3.90\n",
      "8         235      9th Grade  3.15\n",
      "9         nil              9  2.80\n",
      "10        469             11  3.45\n",
      "11        456             10  2.75\n"
     ]
    }
   ],
   "source": [
    "# reads the JSON file and converts it to a Pandas DataFrame\n",
    "df = pd.read_json('files/grade.json')\n",
    "\n",
    "print(df)\n",
    "# What part of the data set needs to be cleaned?\n",
    "# The grades need to be checked, and the student id needs to not be \"nil\"\n",
    "\n",
    "# From PBL learning, what is a good time to clean data?  Hint, remember Garbage in, Garbage out?\n",
    "# you should really check the input because bad input creates bad output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Info\n",
    "\n",
    "Take a look at some features that the Pandas library has that extracts info from the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Extract Column\n",
    "\n",
    "  - This code uses data from the .json file; 'grade.json' to output the student ID's and GPA's with or without an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     GPA\n",
      "0   3.57\n",
      "1   4.00\n",
      "2   2.78\n",
      "3   3.45\n",
      "4   4.75\n",
      "5   3.33\n",
      "6   2.95\n",
      "7   3.90\n",
      "8   3.15\n",
      "9   2.80\n",
      "10  3.45\n",
      "11  2.75\n",
      "\n",
      "Student ID  GPA\n",
      "       123 3.57\n",
      "       246 4.00\n",
      "       578 2.78\n",
      "       469 3.45\n",
      "       324 4.75\n",
      "       313 3.33\n",
      "       145 2.95\n",
      "       167 3.90\n",
      "       235 3.15\n",
      "       nil 2.80\n",
      "       469 3.45\n",
      "       456 2.75\n"
     ]
    }
   ],
   "source": [
    "#print the values in the points column with column header\n",
    "print(df[['GPA']])\n",
    "\n",
    "print()\n",
    "\n",
    "#try two columns and remove the index from print statement\n",
    "print(df[['Student ID','GPA']].to_string(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Sort\n",
    "\n",
    "  - The following code hows to output data by sorting from ascending or descending order by using the 'sort_values' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID Year in School   GPA\n",
      "11        456             10  2.75\n",
      "2         578             12  2.78\n",
      "9         nil              9  2.80\n",
      "6         145             12  2.95\n",
      "8         235      9th Grade  3.15\n",
      "5         313             20  3.33\n",
      "3         469             11  3.45\n",
      "10        469             11  3.45\n",
      "0         123             12  3.57\n",
      "7         167             10  3.90\n",
      "1         246             10  4.00\n",
      "4         324         Junior  4.75\n",
      "\n",
      "   Student ID Year in School   GPA\n",
      "4         324         Junior  4.75\n",
      "1         246             10  4.00\n",
      "7         167             10  3.90\n",
      "0         123             12  3.57\n",
      "3         469             11  3.45\n",
      "10        469             11  3.45\n",
      "5         313             20  3.33\n",
      "8         235      9th Grade  3.15\n",
      "6         145             12  2.95\n",
      "9         nil              9  2.80\n",
      "2         578             12  2.78\n",
      "11        456             10  2.75\n"
     ]
    }
   ],
   "source": [
    "#sort values\n",
    "print(df.sort_values(by=['GPA']))\n",
    "\n",
    "print()\n",
    "\n",
    "#sort the values in reverse order\n",
    "print(df.sort_values(by=['GPA'], ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Selection or Filter\n",
    "\n",
    "  - This simple code only prints data with GPA greater than 3.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID Year in School   GPA\n",
      "0         123             12  3.57\n",
      "1         246             10  4.00\n",
      "3         469             11  3.45\n",
      "4         324         Junior  4.75\n",
      "5         313             20  3.33\n",
      "7         167             10  3.90\n",
      "8         235      9th Grade  3.15\n",
      "10        469             11  3.45\n"
     ]
    }
   ],
   "source": [
    "#print only values with a specific criteria \n",
    "print(df[df.GPA > 3.00])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Selection Max and Min\n",
    "\n",
    "  - similarly to the last code block, this code block selectively only displays the maximum and minimum GPA's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student ID Year in School   GPA\n",
      "4        324         Junior  4.75\n",
      "\n",
      "   Student ID Year in School   GPA\n",
      "11        456             10  2.75\n"
     ]
    }
   ],
   "source": [
    "print(df[df.GPA == df.GPA.max()])\n",
    "print()\n",
    "print(df[df.GPA == df.GPA.min()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your own DataFrame\n",
    "\n",
    "Using Pandas allows you to create your own DataFrame in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Dictionary to Pandas DataFrame\n",
    "\n",
    "  - This code block uses the pandas module to create a dataset from scratch, then the data is printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Dict_to_DF------------------\n",
      "   calories  duration  before  after\n",
      "0       420        50     150    148\n",
      "1       380        40     139    138\n",
      "2       390        45     176    175\n",
      "3    100000         1     200      1\n",
      "----------Dict_to_DF_labels--------------\n",
      "      calories  duration  before  after\n",
      "day1       420        50     150    148\n",
      "day2       380        40     139    138\n",
      "day3       390        45     176    175\n",
      "day4    100000         1     200      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#the data can be stored as a python dictionary\n",
    "dict = {\n",
    "  \"calories\": [420, 380, 390, 100000],\n",
    "  \"duration\": [50, 40, 45, 1],\n",
    "  \"before\": [150, 139, 176, 200],\n",
    "  \"after\": [148, 138, 175, 1]\n",
    "\n",
    "}\n",
    "#stores the data in a data frame\n",
    "print(\"-------------Dict_to_DF------------------\")\n",
    "df = pd.DataFrame(dict)\n",
    "print(df)\n",
    "\n",
    "print(\"----------Dict_to_DF_labels--------------\")\n",
    "\n",
    "#or with the index argument, you can label rows.\n",
    "df = pd.DataFrame(dict, index = [\"day1\", \"day2\", \"day3\", \"day4\"])\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine DataFrame Rows\n",
    "\n",
    "  - This code block allows you to select specific data variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Examine Selected Rows---------\n",
      "      calories  duration  before  after\n",
      "day1       420        50     150    148\n",
      "day3       390        45     176    175\n",
      "--------Examine Single Row-----------\n",
      "calories    420\n",
      "duration     50\n",
      "before      150\n",
      "after       148\n",
      "Name: day1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-------Examine Selected Rows---------\")\n",
    "#use a list for multiple labels:\n",
    "print(df.loc[[\"day1\", \"day3\"]])\n",
    "\n",
    "#refer to the row index:\n",
    "print(\"--------Examine Single Row-----------\")\n",
    "print(df.loc[\"day1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame Information\n",
    "\n",
    "  - this code block uses the 'info' function to provide information like length of the data frame, data-types, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, day1 to day3\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   calories  3 non-null      int64\n",
      " 1   duration  3 non-null      int64\n",
      " 2   before    3 non-null      int64\n",
      " 3   after     3 non-null      int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 228.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#print info about the data set\n",
    "print(df.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of larger data set\n",
    "\n",
    "Pandas can read CSV and many other types of files, run the following code to see more features with a larger data set\n",
    "\n",
    "  - This code block uses the panda module to read the 'data.csv' file and output the data based on the duration of the workout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Duration Top 10---------\n",
      "     Duration  Pulse  Maxpulse  Calories\n",
      "69        300    108       143    1500.2\n",
      "79        270    100       131    1729.0\n",
      "109       210    137       184    1860.4\n",
      "60        210    108       160    1376.0\n",
      "106       180     90       120     800.3\n",
      "90        180    101       127     600.1\n",
      "65        180     90       130     800.4\n",
      "61        160    110       137    1034.4\n",
      "62        160    109       135     853.0\n",
      "67        150    107       130     816.0\n",
      "--Duration Bottom 10------\n",
      "     Duration  Pulse  Maxpulse  Calories\n",
      "68         20    106       136     110.4\n",
      "100        20     95       112      77.7\n",
      "89         20     83       107      50.3\n",
      "135        20    136       156     189.0\n",
      "94         20    150       171     127.4\n",
      "95         20    151       168     229.4\n",
      "139        20    141       162     222.4\n",
      "64         20    110       130     131.4\n",
      "112        15    124       139     124.2\n",
      "93         15     80       100      50.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read csv and sort 'Duration' largest to smallest\n",
    "df = pd.read_csv('files/data.csv').sort_values(by=['Duration'], ascending=False)\n",
    "\n",
    "print(\"--Duration Top 10---------\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"--Duration Bottom 10------\")\n",
    "print(df.tail(10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs are a Source for Writing Programs with Data\n",
    "> 3rd Party APIs are a great source for creating Pandas Data Frames.  \n",
    "- Data can be fetched and resulting json can be placed into a Data Frame\n",
    "- Observe output, this looks very similar to a Database\n",
    "\n",
    "  - This code block gets data from a covid API and displays it below, it looks like a database because the information comes from a database and is displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country_name       cases     deaths\n",
      "0          USA  82,649,779  1,018,316\n",
      "1        India  43,057,545    522,193\n",
      "2       Brazil  30,345,654    662,663\n",
      "3       France  28,244,977    145,020\n",
      "4      Germany  24,109,433    134,624\n",
      "5           UK  21,933,206    173,352\n"
     ]
    }
   ],
   "source": [
    "'''Pandas can be used to analyze data'''\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def fetch():\n",
    "    '''Obtain data from an endpoint'''\n",
    "    url = \"https://flask.nighthawkcodingsociety.com/api/covid/\"\n",
    "    fetch = requests.get(url)\n",
    "    json = fetch.json()\n",
    "\n",
    "    # filter data for requirement\n",
    "    df = pd.DataFrame(json['countries_stat'])  # filter endpoint for country stats\n",
    "    print(df.loc[0:5, 'country_name':'deaths']) # show row 0 through 5 and columns country_name through deaths\n",
    "    \n",
    "fetch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacks\n",
    "> AP Prep\n",
    "- Add this Blog to you own Blogging site.  In the Blog add notes and observations on each code cell.\n",
    "- In blog add College Board practice problems for 2.3.\n",
    "\n",
    "> The next 4 weeks, Teachers want you to improve your understanding of data.  Look at the blog and others on Unit 2.  Your intention is to find some things to differentiate your individual College Board project.\n",
    "- Create or Find your own dataset.  The suggestion is to use a JSON file, integrating with your PBL project would be ***Fambulous***.\n",
    "\n",
    "    When choosing a data set, think about the following:\n",
    "    - Does it have a good sample size?\n",
    "    - Is there bias in the data?\n",
    "    - Does the data set need to be cleaned?\n",
    "    - What is the purpose of the data set?\n",
    "    - ...\n",
    "- Continue this Blog using Pandas extract info from that dataset (ex. max, min, mean, median, mode, etc.)\n",
    "\n",
    "## College board questions\n",
    "\n",
    "|Question|answer|\n",
    "|-|-|\n",
    "|1. Which of the following is an advantage of a lossless compression algorithm over a lossy compression algorithm?|B. A lossless compression algorithm can guarantee reconstruction of original data, while a lossy compression algorithm cannot.|\n",
    "|2. A user wants to save a data file on an online storage site. The user wants to reduce the size of the file, if possible, and wants to be able to completely restore the file to its original version. Which of the following actions best supports the userâ€™s needs?|A. Compressing the file using a lossless compression algorithm before uploading it|\n",
    "|3. A programmer is developing software for a social media platform. The programmer is planning to use compression when users send attachments to other users. Which of the following is a true statement about the use of compression?|C. Lossy compression of an image file generally provides a greater reduction in transmission time than lossless compression does.|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo Finance Dataset\n",
    "\n",
    "This code uses the data from yahoo finance and functions from pandas to display the maximum, minimum, median, and mean stock prices from Apple in the last quarter. As well as displaying all stock data at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Mean price for AAPL in the last quarter: $141.22\n",
      "Median price for AAPL in the last quarter: $142.65\n",
      "Minimum price for AAPL in the last quarter: $125.02\n",
      "Maximum price for AAPL in the last quarter: $155.33\n",
      "data for AAPL in the last quarter: \n",
      "Date\n",
      "2022-12-01    148.309998\n",
      "2022-12-02    147.809998\n",
      "2022-12-05    146.630005\n",
      "2022-12-06    142.910004\n",
      "2022-12-07    140.940002\n",
      "2022-12-08    142.649994\n",
      "2022-12-09    142.160004\n",
      "2022-12-12    144.490005\n",
      "2022-12-13    145.470001\n",
      "2022-12-14    143.210007\n",
      "2022-12-15    136.500000\n",
      "2022-12-16    134.509995\n",
      "2022-12-19    132.369995\n",
      "2022-12-20    132.300003\n",
      "2022-12-21    135.449997\n",
      "2022-12-22    132.229996\n",
      "2022-12-23    131.860001\n",
      "2022-12-27    130.029999\n",
      "2022-12-28    126.040001\n",
      "2022-12-29    129.610001\n",
      "2022-12-30    129.929993\n",
      "2023-01-03    125.070000\n",
      "2023-01-04    126.360001\n",
      "2023-01-05    125.019997\n",
      "2023-01-06    129.619995\n",
      "2023-01-09    130.149994\n",
      "2023-01-10    130.729996\n",
      "2023-01-11    133.490005\n",
      "2023-01-12    133.410004\n",
      "2023-01-13    134.759995\n",
      "2023-01-17    135.940002\n",
      "2023-01-18    135.210007\n",
      "2023-01-19    135.270004\n",
      "2023-01-20    137.869995\n",
      "2023-01-23    141.110001\n",
      "2023-01-24    142.529999\n",
      "2023-01-25    141.860001\n",
      "2023-01-26    143.960007\n",
      "2023-01-27    145.929993\n",
      "2023-01-30    143.000000\n",
      "2023-01-31    144.289993\n",
      "2023-02-01    145.429993\n",
      "2023-02-02    150.820007\n",
      "2023-02-03    154.500000\n",
      "2023-02-06    151.729996\n",
      "2023-02-07    154.649994\n",
      "2023-02-08    151.919998\n",
      "2023-02-09    150.869995\n",
      "2023-02-10    151.009995\n",
      "2023-02-13    153.850006\n",
      "2023-02-14    153.199997\n",
      "2023-02-15    155.330002\n",
      "2023-02-16    153.710007\n",
      "2023-02-17    152.550003\n",
      "2023-02-21    148.479996\n",
      "2023-02-22    148.910004\n",
      "2023-02-23    149.399994\n",
      "2023-02-24    146.710007\n",
      "2023-02-27    147.919998\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Set the ticker symbol and date range\n",
    "ticker = \"AAPL\"\n",
    "start_date = \"2022-12-01\"\n",
    "end_date = \"2023-02-28\"\n",
    "\n",
    "# Get the stock data from Yahoo Finance\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Calculate the mean and median closing prices for the last quarter\n",
    "mean_price = data[\"Close\"].mean()\n",
    "median_price = data[\"Close\"].median()\n",
    "min_price = data[\"Close\"].min()\n",
    "max_price = data[\"Close\"].max()\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean price for {ticker} in the last quarter: ${mean_price:.2f}\")\n",
    "print(f\"Median price for {ticker} in the last quarter: ${median_price:.2f}\")\n",
    "print(f\"Minimum price for {ticker} in the last quarter: ${min_price:.2f}\")\n",
    "print(f\"Maximum price for {ticker} in the last quarter: ${max_price:.2f}\")\n",
    "print(f\"data for {ticker} in the last quarter: \")\n",
    "print(data[\"Close\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65f6bdf080211a4261ca30203f2967d5d410cd9d47d7b7e5694003092334a949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
